{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isavida/football-task/blob/players-tracking/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "_0OlNi-unhDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keemGl--AKn3",
        "outputId": "ff490ca4-04f9-4fc1-eb58-054d2f035236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install this specific YOLO branch which includes weighted loss function\n",
        "!git clone --branch fix#8578 https://github.com/hulkds/ultralytics.git -q\n",
        "!pip install /content/ultralytics/ -q\n",
        "\n",
        "!pip install easyocr -q\n",
        "\n",
        "# Fine-tuning dataset\n",
        "!wget -q -O dataset.zip https://universe.roboflow.com/ds/91Soi5QkdU?key=E6tIgxhinz\n",
        "!unzip -q dataset.zip -d dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bVbutFMSAMle"
      },
      "outputs": [],
      "source": [
        "import colorsys\n",
        "import copy\n",
        "import cv2\n",
        "import easyocr\n",
        "import imutils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from moviepy.editor import *\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.cluster import KMeans\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.data.augment import Albumentations\n",
        "from ultralytics.utils import LOGGER, colorstr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJzRmHXQiva0",
        "outputId": "9d86d769-59b7-4f85-ae85-a99020034730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Augmentation"
      ],
      "metadata": {
        "id": "os4a6qbXvaXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def __init__(self, p=1.0):\n",
        "        \"\"\"Initialize the transform object for YOLO bbox formatted params.\"\"\"\n",
        "        self.p = p\n",
        "        self.transform = None\n",
        "        prefix = colorstr(\"albumentations: \")\n",
        "        try:\n",
        "            import albumentations as A\n",
        "\n",
        "            # check_version(A.__version__, \"1.0.3\", hard=True)  # version requirement\n",
        "\n",
        "            # Transforms\n",
        "            T = [\n",
        "                A.Affine(scale=0.7, rotate = [-20,20], shear=[-45,45], p=0.5, mode=cv2.BORDER_REFLECT),\n",
        "                A.MotionBlur(blur_limit=15, p=0.8),\n",
        "                A.Blur(p=0.5),\n",
        "                A.GaussNoise(),\n",
        "                A.GridDistortion(p=0.5),\n",
        "                A.ToGray(p=0.5),\n",
        "                A.CLAHE(p=0.5),\n",
        "                A.RandomBrightnessContrast(p=0.5),\n",
        "                A.RandomGamma(p=0.5),\n",
        "                A.HueSaturationValue(p=0.5)\n",
        "            ]\n",
        "            self.transform = A.Compose(T, bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"]))\n",
        "\n",
        "            LOGGER.info(prefix + \", \".join(f\"{x}\".replace(\"always_apply=False, \", \"\") for x in T if x.p))\n",
        "        except ImportError:  # package not installed, skip\n",
        "            pass\n",
        "        except Exception as e:\n",
        "            LOGGER.info(f\"{prefix}{e}\")\n",
        "\n",
        "Albumentations.__init__ = __init__\n"
      ],
      "metadata": {
        "id": "DSYJ4Sihve8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gfkpdTXcfbP"
      },
      "source": [
        "# Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-neag0JMcegH",
        "outputId": "7515a6c9-5a69-4ef4-dc78-f1567075120a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 251MB/s]\n"
          ]
        }
      ],
      "source": [
        "training = True\n",
        "model_checkpoint = 'yolov8n.pt'\n",
        "model = YOLO(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sKg1dQLXc1lq"
      },
      "outputs": [],
      "source": [
        "def finetune_model(model, datapath, pos_weight, imgsz=640, epochs=100, patience=10):\n",
        "    return model.train(data=datapath, pos_weight=pos_weight, imgsz=imgsz, epochs=epochs, patience=patience, dropout=0.2)\n",
        "\n",
        "def inference_video(model, filename, persist=False, classes=[0,1,2]):\n",
        "    return model.track(source=filename, save = False, conf=0.1, persist=persist, verbose = False, classes=classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CQqTV0qfFlA"
      },
      "outputs": [],
      "source": [
        "if training:\n",
        "    finetune_model(model, '/content/dataset/data.yaml', pos_weight=[6.0, 1.0, 3.0], imgsz=1088)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA1cwRbrI5sI"
      },
      "source": [
        "#Players detection and team classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf_thpL1Siy5"
      },
      "source": [
        "## Getting colors from scoreboard\n",
        "\n",
        "To correctly classify each player into their team, the team colors should be finded.\n",
        "\n",
        "As a first approach, is proposed to use the **k-means clustering algorithm** to detect the colors of the jerseys from the bounding boxes of the players, processing the image by removing the green background to have the maximum percentage of relevant information possible.\n",
        "\n",
        "This approach does not provide the expected results and also does not provide the information of which equipment belongs to the home team and which to the visiting team, so it was decided to obtain all this information from the **scoreboard**.\n",
        "\n",
        "*Although this notebook does not keep all the code that has been tested for readability, it can be consulted in previous commits.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqklomVPjWG2"
      },
      "source": [
        "###Scoreboard recognition\n",
        "The first step to obtain the scoreboard colors is to recognize the scoreboard itself. To do this, the pixels that remain **static** in several random frames are obtained and a **letter detector** is used to cut out the rectangle containing the scoreboard from the letters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nY1Wk5SWwvYG"
      },
      "outputs": [],
      "source": [
        "def get_static_pixels_from_video(filepath, n_samples=10, std_ratio = 0.04, crop_x_ratio = 0.4, crop_y_ratio = 0.2):\n",
        "    ''' Crop parameters just accelerates the workflow since we know that the\n",
        "    scoreboard is located at the upper-left corner. The reader can test\n",
        "    this function with both crop ratios = 1, which takes around 30 secs using CPU'''\n",
        "    cap = cv2.VideoCapture(filepath)\n",
        "\n",
        "    # Randomly select n sample frames\n",
        "    sample_frames_index = [np.random.randint(0, cap.get(cv2.CAP_PROP_FRAME_COUNT)) for i in range(n_samples)]\n",
        "\n",
        "    # Store selected frames in an array\n",
        "    sample_frames = []\n",
        "    for sfi in sample_frames_index:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, sfi)\n",
        "        _, frame = cap.read()\n",
        "        if frame is not None:\n",
        "            sample_frames.append(frame[0:int(crop_y_ratio * frame.shape[0]),\n",
        "                                0:int(crop_x_ratio * frame.shape[1])])\n",
        "\n",
        "    # std will help to check static pixels\n",
        "    # median obtains a precise scoreboard in case it's damaged on any frame\n",
        "    std_frames = np.std(sample_frames, axis=0).astype(dtype=np.uint8)\n",
        "    median_frames = np.median(sample_frames, axis=0).astype(dtype=np.uint8)\n",
        "\n",
        "    # get mean over color channels\n",
        "    std_frame_mean = np.mean(std_frames/255, axis=2)\n",
        "    std_frame_mean_3D = np.repeat(std_frame_mean[:,:,np.newaxis], 3, axis=2)\n",
        "\n",
        "    # filter static pixels\n",
        "    background = np.where(std_frame_mean_3D < std_ratio, median_frames, 0)\n",
        "\n",
        "    return background\n",
        "\n",
        "def xywh_from_points_with_scale(points_2d, scale=1.2):\n",
        "    ''' Compute center_x, center_y, width and weight given N 2d points '''\n",
        "\n",
        "    x_min = np.min(points_2d[:,0], axis=0)\n",
        "    x_max = np.max(points_2d[:,0], axis=0)\n",
        "    y_min = np.min(points_2d[:,1], axis=0)\n",
        "    y_max = np.max(points_2d[:,1], axis=0)\n",
        "\n",
        "    return [(x_max+x_min)/2,\n",
        "            (y_max+y_min)/2,\n",
        "            (x_max-x_min) * scale,\n",
        "            (y_max-y_min) * scale]\n",
        "\n",
        "def crop_image_given_xywh(image, xywh):\n",
        "    x_min = int(xywh[0] - xywh[2]/2)\n",
        "    x_max = int(xywh[0] + xywh[2]/2)\n",
        "    y_min = int(xywh[1] - xywh[3]/2)\n",
        "    y_max = int(xywh[1] + xywh[3]/2)\n",
        "\n",
        "    return image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "def detect_team_scoreboard_and_crop_image(background):\n",
        "    # read image\n",
        "    img = copy.deepcopy(background)\n",
        "\n",
        "    # instance text detector\n",
        "    reader = easyocr.Reader(['en'], gpu=False)\n",
        "\n",
        "    # detect text on image\n",
        "    text_ = reader.readtext(img)\n",
        "\n",
        "    threshold = 0.25\n",
        "    initials = []\n",
        "\n",
        "    # draw bbox and text of team initials\n",
        "    for t_, t in enumerate(text_):\n",
        "        bbox, text, score = t\n",
        "\n",
        "        if score > threshold and len(text) == 3:\n",
        "            #cv2.rectangle(img, bbox[0], bbox[2], (0, 255, 0), 5)\n",
        "            #cv2.putText(img, text, bbox[0], cv2.FONT_HERSHEY_COMPLEX, 0.65, (255, 0, 0), 2)\n",
        "\n",
        "            initials.append(bbox)\n",
        "\n",
        "    initials_np = np.array(initials)\n",
        "    initials_np = initials_np.reshape(initials_np.shape[0] * initials_np.shape[1], initials_np.shape[2])\n",
        "\n",
        "    xywh = xywh_from_points_with_scale(initials_np)\n",
        "    crop_img = crop_image_given_xywh(img, xywh)\n",
        "\n",
        "    return crop_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uxv0yEnsvwVa"
      },
      "outputs": [],
      "source": [
        "def split_scoreboard_per_team(scoreboard):\n",
        "    img_width = scoreboard.shape[1]\n",
        "    return scoreboard[:,:img_width//2,:], scoreboard[:,img_width//2:,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdB3jSqcmD8m"
      },
      "source": [
        "### Color extraction\n",
        "The second step is to obtain the colors of the scoreboard (the one on the left belongs to the home team and the one on the right belongs to the away team).\n",
        "\n",
        "To do this, we use the k-means clustering algorithm to keep the main colors of the scoreboard. This **quantization** groups the similar colors and facilitates the subsequent comparison. We use to our advantage in this approach the fact that teams wear colors that are easily distinguishable from each other when playing a match.\n",
        "\n",
        "Once this quantization is done, we divide the scoreboard in half and compare the **frequency** of each color on each side to identify which colors are the most distinctive on each side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cpzc8cnkjaDu"
      },
      "outputs": [],
      "source": [
        "def quantize_img(img, K=32):\n",
        "    ''' This function quantize the input image by using k-means algorithm,\n",
        "        dividing the input image in the K most-predominant colors'''\n",
        "    # Preprocess input img\n",
        "    Z = img.reshape((-1,3))\n",
        "    Z = np.float32(Z)\n",
        "\n",
        "    # Specify stopping criteria, max_iters and desired-accuracy\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    #(samples,nclusters,None,criteria,attempts,flags)\n",
        "    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "    # Postprocess back img to original structure\n",
        "    center = np.uint8(center)\n",
        "    res = center[label.flatten()]\n",
        "    quantized_img = res.reshape((img.shape))\n",
        "\n",
        "    return quantized_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GT-7edq4CJeh"
      },
      "outputs": [],
      "source": [
        "def display_colors(colors):\n",
        "    # Create a blank white image\n",
        "    bar = np.zeros((50, 300, 3), dtype=np.uint8)\n",
        "    startX = 0\n",
        "\n",
        "    # For each dominant color, draw a rectangle on the blank image\n",
        "    for color in colors:\n",
        "        endX = startX + (300 // len(colors))\n",
        "        cv2.rectangle(bar, (int(startX), 0), (int(endX), 50), color.astype(int).tolist(), -1)\n",
        "        startX = endX\n",
        "\n",
        "    # Display the image\n",
        "    cv2_imshow(bar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c4VtFhBqf-je"
      },
      "outputs": [],
      "source": [
        "def get_color_frequencies(img):\n",
        "    ''' Get color frequencies and return pd dataframe '''\n",
        "\n",
        "    img_nx3 = np.float32(img.reshape(-1, 3))\n",
        "\n",
        "    unique_pixels, counts = np.unique(img_nx3, axis=0, return_counts=True)\n",
        "\n",
        "    color_dict = {'color': [tuple(color) for color in unique_pixels],\n",
        "                  'frequency': counts}\n",
        "\n",
        "    return pd.DataFrame(color_dict)\n",
        "\n",
        "def get_most_distinctive_color(color_freq_home, color_freq_away, ratio=10):\n",
        "  df_merged = pd.merge(color_freq_home, color_freq_away, on='color', suffixes=('_df1', '_df2'), how='outer')\n",
        "\n",
        "  # Compute difference between frequencies in both dataframes\n",
        "  df_merged['frequency_difference'] = abs(df_merged['frequency_df1']/df_merged['frequency_df2'])\n",
        "\n",
        "  # If the frequencies are bigger than ratio or lower than 1/ratio or Nan(meaning that the color is in one side, but not in the other) is considered a difference to consider\n",
        "  outstanding_differences = df_merged[\n",
        "    (df_merged['frequency_difference'] > ratio) |\n",
        "    (df_merged['frequency_difference'] < 1/ratio) |\n",
        "    (df_merged['frequency_difference'].isna())\n",
        "  ]\n",
        "\n",
        "  # Retrieve the rows with the most frequency for each df from these differences\n",
        "  max_frequency_df1 = outstanding_differences.loc[outstanding_differences['frequency_df1'].idxmax()]\n",
        "  max_frequency_df2 = outstanding_differences.loc[outstanding_differences['frequency_df2'].idxmax()]\n",
        "\n",
        "  return max_frequency_df1['color'], max_frequency_df2['color']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rwNT01HB7UeW"
      },
      "outputs": [],
      "source": [
        "def get_color_per_team_from_video(filepath, kmeans_nclusters=32, color_freq_ratio=10):\n",
        "    ''' Workflow which takes a video as input and return the color assigned to home and away team '''\n",
        "\n",
        "    # Extract scoreboard from video\n",
        "    background = get_static_pixels_from_video(filepath)\n",
        "    scoreboard = detect_team_scoreboard_and_crop_image(background)\n",
        "\n",
        "    # Quantize scoreboard and split in home-away teams\n",
        "    quantized_scoreboard = quantize_img(scoreboard, kmeans_nclusters)\n",
        "    quantized_home_scoreboard, quantized_away_scoreboard = split_scoreboard_per_team(quantized_scoreboard)\n",
        "\n",
        "    # Get color frequency per team\n",
        "    color_frequencies_home_scoreboard = get_color_frequencies(quantized_home_scoreboard)\n",
        "    color_frequencies_away_scoreboard = get_color_frequencies(quantized_away_scoreboard)\n",
        "\n",
        "    # Get the most used color in a team that is mostly never used in the other team\n",
        "    return get_most_distinctive_color(color_frequencies_home_scoreboard, color_frequencies_away_scoreboard, color_freq_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hPwD3D6L9ok0",
        "outputId": "9f2743d5-7cba-4cd0-a512-30a03403c7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n",
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete(35.0, 31.0, 170.0) (126.0, 58.0, 41.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=300x50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAAyCAIAAABptHF9AAAAtUlEQVR4nO3TMRGAMADAQMAGA0NlIaZ+UIkIhlyPfwVZsj/X2FjZPO86gU+OOgD+zoQQMyHETAgxE0LMhBAzIcRMCDETQsyEEDMhxEwIMRNCzIQQMyHETAgxE0LMhBAzIcRMCDETQsyEEDMhxEwIMRNCzIQQMyHETAgxE0LMhBAzIcRMCDETQsyEEDMhxEwIMRNCzIQQMyHETAgxE0LMhBAzIcRMCDETQsyEEDMhxEwIMRNC7AUXGwJFhXABqwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "filepath = '/content/drive/MyDrive/football-task/clip_3.mp4'\n",
        "home_color, away_color = get_color_per_team_from_video(filepath)\n",
        "\n",
        "print(home_color, away_color)\n",
        "display_colors([np.array(home_color), np.array(away_color)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MnmPm7xF4dr"
      },
      "source": [
        "##Color filtering based on team jerseys\n",
        "Once we have obtained from the scoreboard the color of the home team and the color of the away team, we use the OpenCV *cv2.inRange* method to detect the colors in the jerseys that are in a **range** around the colors of the teams.\n",
        "\n",
        "\n",
        "This process is performed in the **HSV color space**, as it allows a better color separation and to take into account aspects such as brightness and saturation, which are important for color detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "K54C_-F8NzAh"
      },
      "outputs": [],
      "source": [
        "def get_color_range(color, h_range=20, s_range=90, v_range=90):\n",
        "  h, s, v= colorsys.rgb_to_hsv(color[2], color[1], color[0])\n",
        "\n",
        "  # translate hsv into opencv space\n",
        "  h = int(180*h)\n",
        "  s = int(255*s)\n",
        "  v = int(v)\n",
        "\n",
        "  low_h=h-h_range\n",
        "  top_h=h+h_range\n",
        "  additionalMask = False\n",
        "\n",
        "  # h coordinates are circular, we have to consider this for red color\n",
        "  if low_h < 0:\n",
        "    new_low_h = low_h + 180\n",
        "    new_top_h = 180\n",
        "    low_h = 0\n",
        "    additionalMask = True\n",
        "  elif top_h>180:\n",
        "    new_top_h = top_h - 180\n",
        "    new_low_h = 0\n",
        "    top_h = 180\n",
        "    additionalMask = True\n",
        "\n",
        "  lower_bound = np.array([low_h, np.clip(s-s_range,0,255), np.clip(v-v_range,0,255)])\n",
        "  upper_bound = np.array([top_h, np.clip(s+s_range,0,255), np.clip(v+v_range,0,255)])\n",
        "\n",
        "  if additionalMask:\n",
        "    additional_lower_bound = np.array([new_low_h, np.clip(s-s_range,0,255), np.clip(v-v_range,0,255)])\n",
        "    additional_upper_bound = np.array([new_top_h, np.clip(s+s_range,0,255), np.clip(v+v_range,0,255)])\n",
        "    return lower_bound, upper_bound, additional_lower_bound, additional_upper_bound\n",
        "\n",
        "  return lower_bound, upper_bound\n",
        "\n",
        "def get_mask(player_hsv, boundaries):\n",
        "\n",
        "  mask = cv2.inRange(player_hsv, boundaries[0], boundaries[1])\n",
        "\n",
        "  if len(boundaries)==4:\n",
        "    mask1 = cv2.inRange(player_hsv, boundaries[2], boundaries[3])\n",
        "    mask = mask + mask1\n",
        "\n",
        "  return mask\n",
        "\n",
        "def team_classification(player, ht_color_boundaries, at_color_boundaries, debug=False):\n",
        "  player_hsv = cv2.cvtColor(player,cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  output_ht = cv2.bitwise_and(player_hsv,player_hsv,mask=get_mask(player_hsv, ht_color_boundaries))\n",
        "  ht_count = np.count_nonzero(output_ht)\n",
        "\n",
        "  output_at = cv2.bitwise_and(player_hsv,player_hsv,mask=get_mask(player_hsv, at_color_boundaries))\n",
        "  at_count = np.count_nonzero(output_at)\n",
        "\n",
        "  tot_count = np.count_nonzero(player_hsv)\n",
        "  #cv2_imshow(player_hsv)\n",
        "  #print(tot_count)\n",
        "  ht_percentage = ht_count/tot_count\n",
        "  at_percentage = at_count/tot_count\n",
        "\n",
        "  if debug:\n",
        "    cv2_imshow(player_hsv)\n",
        "\n",
        "    print('Percentage of pixels home team : ', ht_percentage)\n",
        "    cv2_imshow(output_ht)\n",
        "\n",
        "    print('Percentage of pixels away team  : ', at_percentage)\n",
        "    cv2_imshow(output_at)\n",
        "\n",
        "\n",
        "  if ht_percentage>0.01 and ht_percentage>at_percentage:\n",
        "    return 'Home', home_color\n",
        "\n",
        "  elif at_percentage>0.01 and at_percentage>ht_percentage:\n",
        "    return 'Away', away_color\n",
        "\n",
        "  else:\n",
        "    return 'Not sure', (0.0, 0.0, 0.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "7FFNa-IFvDmx"
      },
      "outputs": [],
      "source": [
        "def get_upper_left_corner_location(coordinates):\n",
        "  ''' YOLO x-y coordinates refers to the center of the detected image.\n",
        "  This functions gets the upper-left corner as a util in order to create the mask of the bounding boxes '''\n",
        "  center_x, center_y, w, h = coordinates\n",
        "  x= int(center_x - w/2)\n",
        "  y= int(center_y - h/2)\n",
        "\n",
        "  return x, y\n",
        "\n",
        "def process_ball(img, bounding_boxes):\n",
        "  final_image = np.copy(img)\n",
        "  x=0\n",
        "  y=0\n",
        "  if bounding_boxes:\n",
        "    box = bounding_boxes[0]\n",
        "    x, y, w, h = map(int, box.xywh.tolist()[0])\n",
        "    x,y = get_upper_left_corner_location([x,y,w,h])\n",
        "    final_image = cv2.rectangle (final_image, (x, y), (x+w,y+h), (255,255,0), 2)\n",
        "    final_image = cv2.putText(final_image, \"Ball\",(x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (0, 0, 0), 2)\n",
        "  return final_image, (x,y)\n",
        "\n",
        "def process_persons(orig_img, bounding_boxes, ht_boundaries, at_boundaries, ball_coords):\n",
        "\n",
        "  ## remove green\n",
        "  hsv = cv2.cvtColor(orig_img, cv2.COLOR_BGR2HSV)\n",
        "  green_mask = cv2.inRange(hsv, (35, 35, 35), (70, 255,255))\n",
        "  inverted_green_mask= cv2.bitwise_not(green_mask)\n",
        "  img_without_green = cv2.bitwise_and(orig_img, orig_img, mask=inverted_green_mask)\n",
        "  final_image = np.copy(orig_img)\n",
        "\n",
        "  count_home_players=0\n",
        "  count_away_players=0\n",
        "  dist_min=1000\n",
        "  dist_thres = 70\n",
        "  for box in bounding_boxes:\n",
        "    x, y, w, h = map(int, box.xywh.tolist()[0])\n",
        "    x,y = get_upper_left_corner_location([x,y,w,h])\n",
        "\n",
        "    if box.cls==1: #cls 1 corresponds to person\n",
        "      player_torso = img_without_green[y:y+(h//2),x:x+w] #crop image to only have the torso\n",
        "      team_text, color_float = team_classification(player_torso, ht_boundaries, at_boundaries, debug=False)\n",
        "      final_image = cv2.rectangle (final_image, (x, y), (x+w,y+h), (int(color_float[0]), int(color_float[1]), int(color_float[2])), 2)\n",
        "      final_image = cv2.putText(final_image, team_text+ ' ID:'+str(int(box.id.item())), (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (0, 0, 0), 2)\n",
        "      #final_image = cv2.putText(str(int(box.conf.item())), (x+w, y+h), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (0, 0, 0), 2)\n",
        "      if ball_coords[0]!=0 and ball_coords[1]!=0:\n",
        "        dist=np.linalg.norm(np.array(ball_coords)- np.array((x+w//2,y+h)))\n",
        "        if dist<dist_min:\n",
        "          dist_min=dist\n",
        "          min_coords = (x+w//2, y-20)\n",
        "\n",
        "      if team_text == 'Home':\n",
        "        count_home_players+=1\n",
        "      elif team_text == 'Away':\n",
        "        count_away_players+=1\n",
        "\n",
        "    elif box.cls==2:\n",
        "      final_image = cv2.rectangle (final_image, (x, y), (x+w,y+h), (0,0,0), 2)\n",
        "      final_image = cv2.putText(final_image,'Referee', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (0, 0, 0), 2)\n",
        "\n",
        "    if dist_min<dist_thres:\n",
        "      final_image = cv2.drawMarker(final_image,min_coords,(0, 255, 238),markerType=cv2.MARKER_TRIANGLE_DOWN,\n",
        "                                           markerSize=30,thickness=2,line_type=cv2.LINE_AA)\n",
        "\n",
        "  return final_image, count_home_players, count_away_players\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNOOYedWo4IR"
      },
      "source": [
        "### Players detection and classification\n",
        "The last step of this process would be to run through the video clip we want to process and use the **YOLO model** to obtain the player detections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjQUOnVC-zH7"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('output'):\n",
        "  os.makedirs('output')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_video = cv2.VideoCapture(f'/content/drive/MyDrive/football-task/clip_3.mp4')\n",
        "width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(input_video.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "model = YOLO('/content/drive/MyDrive/football-task/yolov8n-1088-motionblur/train/weights/best.pt')\n",
        "\n",
        "#create video output with same properties as input\n",
        "output_video = cv2.VideoWriter(f'/content/drive/MyDrive/football-task/yolov8n-1088-motionblur/clip_3_bp.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "home_color_range = get_color_range(home_color)\n",
        "away_color_range = get_color_range(away_color)\n",
        "while input_video.isOpened():\n",
        "  success, frame = input_video.read()\n",
        "  if success:\n",
        "    ball_coords = (0,0)\n",
        "    results_persons = inference_video(model, frame, persist=True, classes=[1,2]) # predict each frame with YOLO model\n",
        "    results_ball = inference_video(model, frame, persist=False, classes=[0]) # predict each frame with YOLO model\n",
        "    for r in results_ball:\n",
        "      processed_img, ball_coords = process_ball(r.orig_img, r.boxes)\n",
        "    for r in results_persons:\n",
        "      new_frame, home_count, away_count = process_persons(processed_img, r.boxes, home_color_range, away_color_range, ball_coords)\n",
        "    output_video.write(new_frame)\n",
        "  else:\n",
        "    break\n",
        "input_video.release()\n",
        "output_video.release()\n"
      ],
      "metadata": {
        "id": "IYq8dZMQi9D3"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbDoBw8JR9z0"
      },
      "outputs": [],
      "source": [
        "input_video = cv2.VideoCapture(f'/content/drive/MyDrive/football-task/clip_3.mp4')\n",
        "width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(input_video.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "model = YOLO('/content/drive/MyDrive/football-task/yolov8n-albumentations/weights/best.pt')\n",
        "\n",
        "#create video output with same properties as input\n",
        "output_video = cv2.VideoWriter(f'/content/drive/MyDrive/football-task/yolov8n-albumentations/clip_3.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "home_color_range = get_color_range(home_color)\n",
        "away_color_range = get_color_range(away_color)\n",
        "last_ball_position = None\n",
        "last_ball_width = None\n",
        "\n",
        "while input_video.isOpened():\n",
        "  success, frame = input_video.read()\n",
        "  if success:\n",
        "    results = inference_video(model, frame) # predict each frame with YOLO model\n",
        "    for r in results:\n",
        "      new_frame, home_count, away_count = get_processed_img(r.orig_img, r.boxes, home_color_range, away_color_range)\n",
        "      output_video.write(new_frame)\n",
        "  else:\n",
        "    break\n",
        "input_video.release()\n",
        "output_video.release()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "os4a6qbXvaXd",
        "pqklomVPjWG2",
        "MdB3jSqcmD8m"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
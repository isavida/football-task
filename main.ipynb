{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSbJevzHP6sXQumxrO3W8a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isavida/football-task/blob/team-classification/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics -q\n",
        "!pip install easyocr -q"
      ],
      "metadata": {
        "id": "keemGl--AKn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colorsys\n",
        "import copy\n",
        "import cv2\n",
        "import easyocr\n",
        "import imutils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.cluster import KMeans\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "bVbutFMSAMle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "dIh51UQTLLUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def git_setup(token):\n",
        "  os.system(f\"git config --global user.email 'isabel.vidaurre@hotmail.com'\")\n",
        "  os.system(f\"git config --global user.name 'isavida'\")\n",
        "  os.system(f\"git clone https://{token}@github.com/isavida/football-task.git\")"
      ],
      "metadata": {
        "id": "986DSJyLhX2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "git_setup('123123')"
      ],
      "metadata": {
        "id": "RXhyzdLKnHdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "The task consists of taking as input a video footage and output:\n",
        "\n",
        "\n",
        "*   A JSONL file that contains a row for each 5th frame with the number of players from home-team and away-team, numbers of referees and position of the ball.\n",
        "*   A video with the team players with the bounding boxes of detections\n",
        "classified according to their team and the annotation of the ball when detected\n",
        "\n",
        "\n",
        "It is decided to do the player detection task first, as the data for the jsonl file can be obtained from these detections.\n",
        "\n"
      ],
      "metadata": {
        "id": "fyv_IupWLbBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Players detection"
      ],
      "metadata": {
        "id": "jA1cwRbrI5sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_video(model, filename):\n",
        "    results = model.track(source=f\"data/{filename}.mp4\", save = False, name=f\"{filename}_result\", conf=0.1, verbose=False)\n",
        "    return results"
      ],
      "metadata": {
        "id": "MJcdW_crAotO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n.pt')\n",
        "video_capture = \"clip_1\"\n",
        "results = inference_video(model, video_capture)"
      ],
      "metadata": {
        "id": "lPfaE9q9AsSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Team classification\n",
        "To correctly classify each team, the team colors should be finded.\n",
        "\n",
        "As a first approach, is proposed to use the **k-means clustering algorithm** to detect the colors of the jerseys from the bounding boxes of the players, processing the image by removing the green background to have the maximum percentage of relevant information possible.\n",
        "\n",
        "This approach does not provide the expected results and also does not provide the information of which equipment belongs to the home team and which to the visiting team, so it was decided to obtain all this information from the **scoreboard**.\n",
        "\n",
        "*Although this notebook does not keep all the code that has been tested for readability, it can be consulted in previous commits.*"
      ],
      "metadata": {
        "id": "5kM3EsqlP7gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting info from scoreboard\n"
      ],
      "metadata": {
        "id": "jf_thpL1Siy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considering that in the task we should distinguish between the home and the away team, another approach could be to identify the colors and the affiliation to the home or the away team by looking at the scoreboard."
      ],
      "metadata": {
        "id": "c2SaueJ3Szkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_static_pixels_from_video(filepath, n_samples=10, std_ratio = 0.04, crop_x_ratio = 0.4, crop_y_ratio = 0.2):\n",
        "    ''' Crop parameters just accelerates the workflow since we know that the\n",
        "    scoreboard is located at the upper-left corner. The reader can test\n",
        "    this function with both crop ratios = 1, which takes around 30 secs using CPU'''\n",
        "    cap = cv2.VideoCapture(filepath)\n",
        "\n",
        "    # Randomly select n sample frames\n",
        "    sample_frames_index = [np.random.randint(0, cap.get(cv2.CAP_PROP_FRAME_COUNT)) for i in range(n_samples)]\n",
        "\n",
        "    # Store selected frames in an array\n",
        "    sample_frames = []\n",
        "    for sfi in sample_frames_index:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, sfi)\n",
        "        _, frame = cap.read()\n",
        "        if frame is not None:\n",
        "            sample_frames.append(frame[0:int(crop_y_ratio * frame.shape[0]),\n",
        "                                0:int(crop_x_ratio * frame.shape[1])])\n",
        "\n",
        "    # std will help to check static pixels\n",
        "    # median obtains a precise scoreboard in case it's damaged on any frame\n",
        "    std_frames = np.std(sample_frames, axis=0).astype(dtype=np.uint8)\n",
        "    median_frames = np.median(sample_frames, axis=0).astype(dtype=np.uint8)\n",
        "\n",
        "    # get mean over color channels\n",
        "    std_frame_mean = np.mean(std_frames/255, axis=2)\n",
        "    std_frame_mean_3D = np.repeat(std_frame_mean[:,:,np.newaxis], 3, axis=2)\n",
        "\n",
        "    # filter static pixels\n",
        "    background = np.where(std_frame_mean_3D < std_ratio, median_frames, 0)\n",
        "\n",
        "    return background\n",
        "\n",
        "def xywh_from_points_with_scale(points_2d, scale=1.2):\n",
        "    ''' Compute center_x, center_y, width and weight given N 2d points '''\n",
        "\n",
        "    x_min = np.min(points_2d[:,0], axis=0)\n",
        "    x_max = np.max(points_2d[:,0], axis=0)\n",
        "    y_min = np.min(points_2d[:,1], axis=0)\n",
        "    y_max = np.max(points_2d[:,1], axis=0)\n",
        "\n",
        "    return [(x_max+x_min)/2,\n",
        "            (y_max+y_min)/2,\n",
        "            (x_max-x_min) * scale,\n",
        "            (y_max-y_min) * scale]\n",
        "\n",
        "def crop_image_given_xywh(image, xywh):\n",
        "    x_min = int(xywh[0] - xywh[2]/2)\n",
        "    x_max = int(xywh[0] + xywh[2]/2)\n",
        "    y_min = int(xywh[1] - xywh[3]/2)\n",
        "    y_max = int(xywh[1] + xywh[3]/2)\n",
        "\n",
        "    return image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "def detect_team_scoreboard_and_crop_image(background):\n",
        "    # read image\n",
        "    img = copy.deepcopy(background)\n",
        "\n",
        "    # instance text detector\n",
        "    reader = easyocr.Reader(['en'], gpu=False)\n",
        "\n",
        "    # detect text on image\n",
        "    text_ = reader.readtext(img)\n",
        "\n",
        "    threshold = 0.25\n",
        "    initials = []\n",
        "\n",
        "    # draw bbox and text of team initials\n",
        "    for t_, t in enumerate(text_):\n",
        "        bbox, text, score = t\n",
        "\n",
        "        if score > threshold and len(text) == 3:\n",
        "            #cv2.rectangle(img, bbox[0], bbox[2], (0, 255, 0), 5)\n",
        "            #cv2.putText(img, text, bbox[0], cv2.FONT_HERSHEY_COMPLEX, 0.65, (255, 0, 0), 2)\n",
        "\n",
        "            initials.append(bbox)\n",
        "\n",
        "    initials_np = np.array(initials)\n",
        "    initials_np = initials_np.reshape(initials_np.shape[0] * initials_np.shape[1], initials_np.shape[2])\n",
        "\n",
        "    xywh = xywh_from_points_with_scale(initials_np)\n",
        "    crop_img = crop_image_given_xywh(img, xywh)\n",
        "\n",
        "    return crop_img\n"
      ],
      "metadata": {
        "id": "nY1Wk5SWwvYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_scoreboard_per_team(scoreboard):\n",
        "    img_width = scoreboard.shape[1]\n",
        "    return scoreboard[:,:img_width//2,:], scoreboard[:,img_width//2:,:]"
      ],
      "metadata": {
        "id": "uxv0yEnsvwVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize_img(img, K=32):\n",
        "    ''' This function quantize the input image by using k-means algorithm,\n",
        "        dividing the input image in the K most-predominant colors'''\n",
        "    # Preprocess input img\n",
        "    Z = img.reshape((-1,3))\n",
        "    Z = np.float32(Z)\n",
        "\n",
        "    # Specify stopping criteria, max_iters and desired-accuracy\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    #(samples,nclusters,None,criteria,attempts,flags)\n",
        "    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "    # Postprocess back img to original structure\n",
        "    center = np.uint8(center)\n",
        "    res = center[label.flatten()]\n",
        "    quantized_img = res.reshape((img.shape))\n",
        "\n",
        "    return quantized_img"
      ],
      "metadata": {
        "id": "cpzc8cnkjaDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_dominant_colors(dominant_colors):\n",
        "    # Create a blank white image\n",
        "    bar = np.zeros((50, 300, 3), dtype=np.uint8)\n",
        "    startX = 0\n",
        "\n",
        "    # For each dominant color, draw a rectangle on the blank image\n",
        "    for color in dominant_colors:\n",
        "        endX = startX + (300 // len(dominant_colors))\n",
        "        cv2.rectangle(bar, (int(startX), 0), (int(endX), 50), color.astype(int).tolist(), -1)\n",
        "        startX = endX\n",
        "\n",
        "    # Display the image\n",
        "    cv2_imshow(bar)"
      ],
      "metadata": {
        "id": "GT-7edq4CJeh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4c1d9988-70bf-4477-cf78-d26a9adfa1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def quantize_img(img, div=32):\\n    \\n    return img // div * div + div // 2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_color_frequencies(img):\n",
        "    ''' Get color frequencies and return pd dataframe '''\n",
        "\n",
        "    img_nx3 = np.float32(img.reshape(-1, 3))\n",
        "\n",
        "    unique_pixels, counts = np.unique(img_nx3, axis=0, return_counts=True)\n",
        "\n",
        "    color_dict = {'color': [tuple(color) for color in unique_pixels],\n",
        "                  'frequency': counts}\n",
        "\n",
        "    return pd.DataFrame(color_dict)\n",
        "\n",
        "def get_most_distinctive_color(color_freq_home, color_freq_away, ratio=10):\n",
        "  df_merged = pd.merge(color_freq_home, color_freq_away, on='color', suffixes=('_df1', '_df2'), how='outer')\n",
        "\n",
        "  # Compute difference between frequencies in both dataframes\n",
        "  df_merged['frequency_difference'] = abs(df_merged['frequency_df1']/df_merged['frequency_df2'])\n",
        "\n",
        "  # If the frequencies are bigger than ratio or lower than 1/ratio or Nan(meaning that the color is in one side, but not in the other) is considered a difference to consider\n",
        "  outstanding_differences = df_merged[\n",
        "    (df_merged['frequency_difference'] > ratio) |\n",
        "    (df_merged['frequency_difference'] < 1/ratio) |\n",
        "    (df_merged['frequency_difference'].isna())\n",
        "  ]\n",
        "\n",
        "  # Retrieve the rows with the most frequency for each df from these differences\n",
        "  max_frequency_df1 = outstanding_differences.loc[outstanding_differences['frequency_df1'].idxmax()]\n",
        "  max_frequency_df2 = outstanding_differences.loc[outstanding_differences['frequency_df2'].idxmax()]\n",
        "\n",
        "  return max_frequency_df1['color'], max_frequency_df2['color']\n"
      ],
      "metadata": {
        "id": "c4VtFhBqf-je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_color_per_team_from_video(filepath, kmeans_nclusters=32, color_freq_ratio=10):\n",
        "    ''' Workflow which takes a video as input and return the color assigned to home and away team '''\n",
        "\n",
        "    # Extract scoreboard from video\n",
        "    background = get_static_pixels_from_video(filepath)\n",
        "    scoreboard = detect_team_scoreboard_and_crop_image(background)\n",
        "\n",
        "    # Quantize scoreboard and split in home-away teams\n",
        "    quantized_scoreboard = quantize_img(scoreboard, kmeans_nclusters)\n",
        "    quantized_home_scoreboard, quantized_away_scoreboard = split_scoreboard_per_team(quantized_scoreboard)\n",
        "\n",
        "    # Get color frequency per team\n",
        "    color_frequencies_home_scoreboard = get_color_frequencies(quantized_home_scoreboard)\n",
        "    color_frequencies_away_scoreboard = get_color_frequencies(quantized_away_scoreboard)\n",
        "\n",
        "    # Get the most used color in a team that is mostly never used in the other team\n",
        "    return get_most_distinctive_color(color_frequencies_home_scoreboard, color_frequencies_away_scoreboard, color_freq_ratio)"
      ],
      "metadata": {
        "id": "rwNT01HB7UeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = f\"data/{video_capture}.mp4\"\n",
        "home_color, away_color = get_color_per_team_from_video(filepath)\n",
        "\n",
        "print(home_color, away_color)\n",
        "display_dominant_colors([np.array(home_color), np.array(away_color)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "hPwD3D6L9ok0",
        "outputId": "fe78287a-361a-4c29-fd50-13136041678f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49.0, 17.0, 211.0) (115.0, 56.0, 27.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=300x50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAAyCAIAAABptHF9AAAAtUlEQVR4nO3TMRGAMADAQMABKphrgan+MYQIhlyPfwVZsj/n2FjZvO46gU+OOgD+zoQQMyHETAgxE0LMhBAzIcRMCDETQsyEEDMhxEwIMRNCzIQQMyHETAgxE0LMhBAzIcRMCDETQsyEEDMhxEwIMRNCzIQQMyHETAgxE0LMhBAzIcRMCDETQsyEEDMhxEwIMRNCzIQQMyHETAgxE0LMhBAzIcRMCDETQsyEEDMhxEwIMRNC7AX+WwIqc0vVuwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Players classification"
      ],
      "metadata": {
        "id": "0MnmPm7xF4dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_upper_left_corner_location(coordinates):\n",
        "  ''' YOLO x-y coordinates refers to the center of the detected image.\n",
        "  This functions gets the upper-left corner as a util in order to create the mask of the bounding boxes '''\n",
        "  center_x, center_y, w, h = coordinates\n",
        "  x= int(center_x - w/2)\n",
        "  y= int(center_y - h/2)\n",
        "\n",
        "  return x, y\n"
      ],
      "metadata": {
        "id": "ziZxKn2HVhta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_persons_images(orig_img, bounding_boxes):\n",
        "  persons=[]\n",
        "  ## remove green\n",
        "  hsv = cv2.cvtColor(orig_img, cv2.COLOR_BGR2HSV)\n",
        "  green_mask = cv2.inRange(hsv, (35, 35, 35), (70, 255,255))\n",
        "  inverted_green_mask= cv2.bitwise_not(green_mask)\n",
        "  processed_img = cv2.bitwise_and(orig_img,orig_img, mask=inverted_green_mask)\n",
        "\n",
        "  for box in bounding_boxes:\n",
        "    x, y, w, h=map(int, box.xywh.tolist()[0])\n",
        "    x,y = get_upper_left_corner_location([int(x),y,w,h])\n",
        "\n",
        "    if box.cls==0: #cls 0 corresponds to person\n",
        "      person=processed_img[y:y+h,x:x+w]\n",
        "      persons.append(person)\n",
        "\n",
        "  return persons"
      ],
      "metadata": {
        "id": "7FFNa-IFvDmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtaining the frame with more person detections\n",
        "max=0\n",
        "max_id=0\n",
        "for i,r in enumerate(results):\n",
        "  length = len(r.boxes.cls==0)\n",
        "  if length>max:\n",
        "    max=length\n",
        "    max_id=i"
      ],
      "metadata": {
        "id": "Sqrn1uHg2KKe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}